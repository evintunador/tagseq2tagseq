# DS2DS Generation Implementation Meta-Plan

## Overview
This document provides a detailed, dependency-ordered plan for implementing the generation functionality for the DS2DS (DAG Sequence to DAG Sequence, or more formally "text-attributed document directed acyclic graph to text-attributed document directed acyclic graph") model. Tasks are categorized by difficulty level to facilitate orchestration across multiple agents.

**Difficulty Levels:**
- **EASY**: Sub-agent can implement with one-time prompt (minimal context, clear spec)
- **MEDIUM**: Primary agent with optional clarifying questions (moderate complexity, some design decisions)
- **HARD**: Primary agent after extensive conversation (complex, significant design decisions, integration challenges)

---

## Phase 1: Foundation Components

### 1.1 DocumentCorpus Class (EASY)
**File**: `experiments/dagseq2dagseq/model/document_corpus.py`

**Dependencies**: None

**Description**: Create a wrapper class around GraphIndex and PretokShardedBackend to provide a clean interface for corpus access during generation.

**Requirements**:
- Wrap `GraphIndex` and `PretokShardedBackend`
- Provide `__init__(dataset_path: Path)` constructor
- Implement `get_document(title: str) -> Optional[np.ndarray]` method that returns tokens
- Implement `has_document(title: str) -> bool` method
- Implement `get_title_variants(title: str) -> List[str]` for fuzzy matching (return exact match only for MVP)
- Implement `close()` method to close backend resources
- Add `__enter__` and `__exit__` for context manager support

**Testing**: Simple unit tests loading a small corpus and retrieving documents

---

### 1.2 Title Normalization Utilities (EASY)
**File**: `experiments/dagseq2dagseq/model/title_utils.py`

**Dependencies**: None

**Description**: Utilities for normalizing titles and generating hashes, matching the training data format used in `data/pretokenize.py`.

**Requirements**:
- Implement `normalize_title(title: str) -> str`: 
  - Lowercase the title
  - Replace spaces with underscores  
  - Keep only alphanumeric characters and underscores
  - Match the scheme used in `data/pretokenize.py` (derives filename from basename)
  
- Implement `generate_title_hash(title: str) -> str`: 
  - Create deterministic 6-character hex hash from the original title
  - Use first 6 chars of md5 or sha256 hash of the title
  - Must be deterministic: same title always produces same hash
  
- Implement `create_filename(title: str) -> str`: 
  - Returns `f"{normalize_title(title)}_{generate_title_hash(title)}"`
  - Example: "New Topic" → "new_topic_3a7f2c"
  
- Implement `strip_hash(title_with_hash: str) -> str`: 
  - Remove `_[0-9a-f]{6}` suffix using regex
  - Example: "new_topic_3a7f2c" → "new_topic"
  
- **Optional** (design decision needed): Implement reverse lookup capability
  - Option A: `get_possible_titles_from_normalized(normalized: str) -> str` (regex pattern)
  - Option B: `get_title_from_normalized(normalized: str, original_title: str) -> bool` (verify hash matches)
  - Since hash is deterministic, we could theoretically search through candidate titles
  - Implementation note: This may not be worth the complexity for MVP; defer if unclear

**Notes**: 
- Hash generation must match training exactly for corpus compatibility
- During training, markdown files are named with this scheme: `title_hash.md`
- The model learns to predict the original title (without hash), but files use normalized+hashed names

**Testing**: 
- Test with known Wikipedia titles from training data
- Verify `create_filename("Python")` matches actual training corpus filenames
- Test round-trip: title → normalized+hash → strip_hash → normalized title
- Test hash determinism: same title always produces same hash

---

### 1.3 GenerationResult Data Structures (EASY)
**File**: `experiments/dagseq2dagseq/model/generation_result.py`

**Dependencies**: 
- Title utilities (1.2) - for normalized title handling

**Description**: Define data structures for generation outputs.

**Requirements**:
```python
from dataclasses import dataclass
from typing import List, Literal, Optional, Union
from pathlib import Path
import numpy as np

@dataclass
class GeneratedDocument:
    """Represents a single document in the generation result."""
    title: str  # Original title as generated by model (non-normalized, no hash)
    title_normalized: str  # Normalized+hashed title for filesystem (e.g., "new_topic_3a7f2c")
    tokens: Optional[np.ndarray]  # Token IDs (may be None for corpus docs if only text loaded)
    text: Optional[str]  # Decoded text (may be None if only tokens stored)
    source: Union[Literal["generated", "corpus"], Path]  # Where doc came from; Path for corpus
    is_root: bool  # Whether this is the root document
    parent_title: Optional[str]  # Title of document that linked to this one (None for root)
    
    # Note: At least one of tokens or text must be non-None
    
@dataclass
class GenerationResult:
    """Complete result of a generation run."""
    root_document: GeneratedDocument
    auxiliary_documents: List[GeneratedDocument]  
    # Ordering: Topologically sorted where possible (dependencies before dependents),
    # with ties broken by creation/access order.
    # Future: Could use a graph structure with explicit edges, but list is simpler for MVP.
    
    # Metadata
    generation_config: dict  # Parameters used for generation
    
    def get_all_documents(self) -> List[GeneratedDocument]:
        """Return all documents (root + auxiliary) in order."""
        return [self.root_document] + self.auxiliary_documents
    
    def get_document_by_title(self, title: str) -> Optional[GeneratedDocument]:
        """Retrieve a document by its title (matches both original and normalized)."""
        for doc in self.get_all_documents():
            if doc.title == title or doc.title_normalized == title:
                return doc
        return None
```

**Design Notes**:
- `tokens` and `text` are both Optional to allow flexibility (corpus docs may only have text, generated may only have tokens initially)
- `source` can be a Path for corpus documents to track original file location
- Auxiliary documents stored in a list for MVP; could evolve to explicit graph structure later
- Topological ordering helps with visualization and understanding generation flow

**Testing**: 
- Simple instantiation tests
- Test `get_document_by_title()` with both original and normalized titles
- Test `get_all_documents()` returns correct order

---

### 1.4 Link Detection Module (MEDIUM)
**File**: `experiments/dagseq2dagseq/model/link_detector.py`

**Dependencies**: None (but needs tiktoken for token ID constants)

**Description**: Detect markdown links in token sequences during generation.

**Requirements**:
- Class `LinkDetector` with configurable token IDs for `[`, `](`, `)`
- Default to GPT-2 token IDs (MUST BE VERIFIED with tiktoken before implementation):
  - `[` candidates: [58, 685] (single char `[` and space+`[`)
  - `](` token: 16151
  - `)` token: 8
  - **Action**: Run `tiktoken.get_encoding("gpt2").encode("[")` etc. to verify these IDs
- Method `detect_link_at_position(tokens: np.ndarray, end_pos: int) -> Optional[DetectedLink]`
  - Given a position where `)` token was just generated, check backwards for valid link structure
  - Return `DetectedLink(start_pos, mid_pos, end_pos, link_text_tokens, target_tokens)` or None
- Use stack-based algorithm to handle nested parentheses correctly
- Only detect complete, valid links: `[text](target)` where brackets are balanced

**Data Structure**:
```python
@dataclass
class DetectedLink:
    """Represents a detected markdown link in token sequence."""
    bracket_open_pos: int  # Position of '[' token
    bracket_close_pos: int  # Position of ']' token  
    paren_open_pos: int  # Position of '(' token (same as bracket_close_pos + 1 if using '](' token)
    paren_close_pos: int  # Position of ')' token
    link_text_tokens: np.ndarray  # Tokens between '[' and ']'
    target_tokens: np.ndarray  # Tokens between '(' and ')'
```

**Algorithm**:
1. When `)` token generated at position `pos`, search backwards
2. Find matching `](` token (must have both parts)
3. From `](` position, search backwards for `[` token
4. Validate: no other `)` tokens between `[` and `]`
5. Extract token ranges and return DetectedLink

**Testing**: 
- Test with valid links: `[text](target)`
- Test with nested parens in text: `[text (with parens)](target)`
- Test with incomplete links: `[text` (should return None)
- Test with non-link brackets: `just [some] text` (should return None)

---

### 1.5 Token Sampling Utilities (EASY)
**File**: `experiments/dagseq2dagseq/model/sampling.py`

**Dependencies**: None

**Description**: Helper functions for sampling next tokens from logits.

**Requirements**:
- `sample_token(logits: torch.Tensor, temperature: float, top_k: Optional[int], top_p: Optional[float]) -> int`
  - Apply temperature scaling
  - Apply top-k filtering if specified
  - Apply nucleus (top-p) sampling if specified
  - Sample from resulting distribution
- `greedy_sample(logits: torch.Tensor) -> int`: Return argmax token
- Handle edge cases (temperature=0 → greedy, empty distributions after filtering)

**Testing**: Unit tests with mock logits distributions

---

## Phase 2: Core Generation Context Management

### 2.1 DocumentContext Class (HARD)
**File**: `experiments/dagseq2dagseq/model/document_context.py`

**Dependencies**: 
- GenerationResult structures (1.2)
- Title utilities (1.3)
- LinkDetector (1.4)

**Description**: Manages the context window during generation, tracking multiple documents, their tokens, and doc_spans for FlexAttention.

**Requirements**:

**State Management**:
- Track all documents in context (root + auxiliary)
- Track which documents are "active" (in context for attention) vs "archived" (removed due to space limits)
- Maintain `doc_spans: List[DocSpan]` for FlexAttention
- Maintain `tokens: torch.Tensor` for the full packed sequence
- Track current generation target (which document we're generating)

**Key Methods**:
```python
class DocumentContext:
    def __init__(
        self,
        max_context_length: int,
        max_tokens_per_doc: int,
        eviction_policy: Literal["drop_oldest", "stop_new"],
        tokenizer_encode: Callable[[str], List[int]],
        tokenizer_decode: Callable[[List[int]], str],
        device: torch.device
    ):
        """Initialize context manager."""
        
    def initialize_root(self, prompt_tokens: np.ndarray, title: str = "Root Document"):
        """Set up the root document as the initial context."""
        
    def add_corpus_document(
        self, 
        title: str, 
        tokens: np.ndarray,
        linked_from_title: str
    ) -> bool:
        """Add a document from corpus. Returns True if added, False if space limit hit."""
        
    def start_auxiliary_generation(
        self, 
        title: str, 
        linked_from_title: str
    ) -> bool:
        """Begin generating a new auxiliary document. Returns True if started, False if limit hit."""
        
    def append_token_to_current(self, token_id: int) -> bool:
        """
        Append token to currently-generating document.
        Returns False if document hits length limit, True otherwise.
        """
        
    def complete_current_document(self):
        """Mark current document generation as complete."""
        
    def switch_to_document(self, title: str):
        """Switch generation target to an existing document (e.g., return to root)."""
        
    def get_tokens_for_model(self) -> torch.Tensor:
        """Return packed token sequence for model input [1, T]."""
        
    def get_doc_spans(self) -> List[DocSpan]:
        """Return current doc_spans for block mask creation."""
        
    def can_add_document(self) -> Tuple[bool, Optional[str]]:
        """Check if we can add another document. Returns (can_add, reason_if_not)."""
        
    def evict_if_needed(self):
        """Apply eviction policy if context is full."""
        
    def get_all_documents(self) -> List[GeneratedDocument]:
        """Return all documents (active + archived) as GeneratedDocument objects."""
```

**Complexity Notes**:
- Must handle token sequence concatenation efficiently
- Must update doc_spans when documents are added/removed/grown
- Must handle eviction: remove oldest auxiliary doc, adjust all indices
- Must track parent relationships for link graph
- Must handle switching between documents during recursive generation

**Testing**: 
- Test adding documents up to limit
- Test eviction policies
- Test doc_span index management
- Test switching between documents

---

### 2.2 GenerationConfig Dataclass (EASY)
**File**: `experiments/dagseq2dagseq/model/generation_config.py`

**Dependencies**: None

**Description**: Configuration object for generation parameters.

**Requirements**:
```python
@dataclass
class GenerationConfig:
    """Configuration for generation behavior."""
    
    # Basic generation params
    max_new_tokens: int = 100
    temperature: float = 1.0
    top_k: Optional[int] = None
    top_p: Optional[float] = None
    
    # Document structure params
    max_tokens_per_document: int = 512
    max_context_length: int = 2048
    max_auxiliary_documents: int = 5
    max_link_depth: int = 1
    
    # Corpus integration
    allow_corpus_fallback: bool = True  # Generate if corpus doesn't have doc
    
    # Eviction policy
    eviction_policy: Literal["drop_oldest", "stop_new"] = "drop_oldest"
    
    # Link handling
    process_prompt_links: bool = True  # Process links in initial prompt
    allow_recursive_links: bool = True  # Allow aux docs to create links (respects max_link_depth)
    
    # Stopping
    eos_token_id: int = 50256  # GPT-2 <|endoftext|>
    
    # Device
    device: str = "cuda" if torch.cuda.is_available() else "cpu"
    
    def to_dict(self) -> dict:
        """Convert to dictionary for metadata storage."""
        return asdict(self)
```

**Testing**: Simple instantiation and validation

---

## Phase 3: Generation Loop Implementation

### 3.1 Single Document Generator (MEDIUM)
**File**: `experiments/dagseq2dagseq/model/single_doc_generator.py`

**Dependencies**:
- DocumentContext (2.1)
- GenerationConfig (2.2)
- Sampling utilities (1.5)
- LinkDetector (1.4)

**Description**: Generate a single document autoregressively without handling links (baseline case).

**Requirements**:
- Class `SingleDocumentGenerator`
- Method `generate(model, context: DocumentContext, config: GenerationConfig) -> int`
  - Generate tokens for current document in context
  - Use model's forward_inference to get next token logits
  - Apply sampling strategy
  - Stop at EOS or max_tokens_per_document
  - Return number of tokens generated
- Handle block mask creation via model's block_mask_creator
- No link detection/handling

**Purpose**: Building block for more complex generation, easier to test

**Testing**:
- Test with simple prompts
- Verify stopping conditions
- Verify tokens are added to context correctly

---

### 3.2 Prompt Link Processor (MEDIUM)
**File**: `experiments/dagseq2dagseq/model/prompt_processor.py`

**Dependencies**:
- LinkDetector (1.4)
- DocumentContext (2.1)
- DocumentCorpus (1.1)
- Title utilities (1.2)

**Description**: Process links that already exist in the initial prompt before generation starts.

**Requirements**:
- Class `PromptLinkProcessor`
- Method `process_prompt(prompt_tokens: np.ndarray, context: DocumentContext, corpus: Optional[DocumentCorpus], config: GenerationConfig) -> List[str]`
  - Scan prompt_tokens for existing links using LinkDetector
  - For each link found:
    - Extract target title
    - If corpus provided and has document: add corpus document to context
    - Elif config.allow_corpus_fallback: create empty document placeholder for later generation
    - Track which documents need generation
  - Return list of document titles that need to be generated
- Handle multiple links in prompt
- Respect max_link_depth (links in prompt count as depth 0 → 1)

**Testing**:
- Test prompt with no links
- Test prompt with corpus-backed links
- Test prompt with links needing generation
- Test mixed scenario

---

### 3.3 Linked Document Generator (HARD)
**File**: `experiments/dagseq2dagseq/model/linked_doc_generator.py`

**Dependencies**:
- SingleDocumentGenerator (3.1)
- PromptLinkProcessor (3.2)
- LinkDetector (1.4)
- DocumentContext (2.1)
- DocumentCorpus (1.1)
- Title utilities (1.2)
- Sampling utilities (1.5)

**Description**: Main generation logic that handles link detection and recursive document generation.

**Requirements**:

**Core Algorithm**:
```
generate_with_links(model, context, corpus, config):
    1. Initialize root document in context
    2. Process any links in prompt
    3. While root document not complete:
        a. Generate next token using model
        b. Append to context
        c. If token is ')':
            - Check for link using LinkDetector
            - If link found:
                - Extract target title
                - Check current depth vs max_link_depth
                - If depth allows:
                    - Check corpus for document
                    - If in corpus: add to context
                    - Elif allow_corpus_fallback:
                        - Start auxiliary generation
                        - Recursively generate that document
                        - Return to root generation
        d. Check stopping conditions (EOS, max tokens)
    4. Return GenerationResult
```

**Key Methods**:
```python
class LinkedDocumentGenerator:
    def __init__(
        self,
        model: DS2DSModel,
        tokenizer_encode: Callable,
        tokenizer_decode: Callable
    ):
        """Initialize generator with model and tokenizer."""
        
    def generate(
        self,
        prompt: Optional[str] = None,
        prompt_tokens: Optional[np.ndarray] = None,
        corpus: Optional[DocumentCorpus] = None,
        config: GenerationConfig = GenerationConfig()
    ) -> GenerationResult:
        """Main generation entry point."""
        
    def _generate_document_recursive(
        self,
        context: DocumentContext,
        corpus: Optional[DocumentCorpus],
        config: GenerationConfig,
        current_depth: int,
        target_doc_title: str
    ) -> int:
        """
        Generate a single document, potentially recursively generating linked documents.
        Returns number of tokens generated.
        """
        
    def _handle_detected_link(
        self,
        link: DetectedLink,
        context: DocumentContext,
        corpus: Optional[DocumentCorpus],
        config: GenerationConfig,
        current_depth: int,
        current_doc_title: str
    ):
        """Process a detected link: add corpus doc or generate new one."""
        
    def _check_stopping_condition(
        self,
        token_id: int,
        tokens_generated: int,
        config: GenerationConfig
    ) -> Tuple[bool, str]:
        """Check if generation should stop. Returns (should_stop, reason)."""
```

**Complexity Notes**:
- Must handle recursion depth tracking
- Must switch context between documents correctly
- Must handle corpus lookups and fallback generation
- Must handle every-token link detection efficiently
- Must respect all generation limits (tokens, depth, auxiliary docs)
- Must handle eviction during generation

**Testing**:
- Test basic generation without links
- Test generation with single link (corpus)
- Test generation with single link (generated)
- Test generation with multiple links
- Test max_link_depth enforcement
- Test eviction scenarios
- Test stopping conditions

---

## Phase 4: Model Integration

### 4.1 Implement forward_inference in DS2DSModel (MEDIUM)
**File**: `experiments/dagseq2dagseq/model/model.py` (modify existing)

**Dependencies**: None (existing model structure)

**Description**: Implement the forward_inference method that was stubbed out in DS2DSModel.

**Requirements**:
- Remove `NotImplementedError` from `forward_inference` method
- Implement the TODO steps from the docstring:
  1. Create block_mask from tokens and doc_spans using self.block_mask_creator
  2. Embed tokens using self.embedding_weight
  3. Pass through self.backbone with block_mask
  4. Apply self.norm
  5. Project to vocabulary using self.lm_head_weight (F.linear)
  6. Return logits of shape (B, T, V)
- Handle dtype and device correctly
- Support optional doc_spans (for non-graph generation)

**Implementation**:
```python
def forward_inference(
    self,
    tokens: Tensor,
    doc_spans: Optional[List[Any]] = None,
    **kwargs
) -> Tensor:
    """Forward pass for inference: tokens in, logits out."""
    # Create block_mask
    batch_dict = {'tokens': tokens}
    if doc_spans is not None:
        batch_dict['doc_spans'] = doc_spans
    batch_dict.update(kwargs)
    
    block_mask = self.block_mask_creator(**batch_dict)
    
    # Input is full sequence; we use all tokens for inference
    x = torch.nn.functional.embedding(tokens, self.embedding_weight)
    x = self.backbone(x, block_mask=block_mask)
    x = self.norm(x)
    
    # Project to vocabulary
    logits = torch.nn.functional.linear(x, self.lm_head_weight)
    
    return logits  # [B, T, V]
```

**Testing**:
- Test with single document (no doc_spans)
- Test with multiple documents (with doc_spans)
- Test shape and dtype of outputs
- Test that gradients are not required (eval mode)

---

### 4.2 Implement generate in DS2DSModel (EASY)
**File**: `experiments/dagseq2dagseq/model/model.py` (modify existing)

**Dependencies**:
- LinkedDocumentGenerator (3.3)
- GenerationConfig (2.2)
- DocumentCorpus (1.1)

**Description**: Implement the high-level generate method that delegates to LinkedDocumentGenerator.

**Requirements**:
- Remove `NotImplementedError` from `generate` method
- Create LinkedDocumentGenerator instance
- Delegate to generator.generate()
- Return GenerationResult
- Handle tokenizer (assume GPT-2 for MVP, make it a parameter later)

**Implementation**:
```python
def generate(
    self,
    prompt: Optional[str] = None,
    prompt_tokens: Optional[Tensor] = None,
    corpus: Optional[DocumentCorpus] = None,
    max_new_tokens: int = 100,
    temperature: float = 1.0,
    top_k: Optional[int] = None,
    top_p: Optional[float] = None,
    max_tokens_per_document: int = 512,
    max_auxiliary_documents: int = 5,
    max_link_depth: int = 1,
    allow_corpus_fallback: bool = True,
    eviction_policy: str = "drop_oldest",
    **kwargs
) -> GenerationResult:
    """Generate text using graph-aware attention patterns."""
    import tiktoken
    enc = tiktoken.get_encoding("gpt2")
    
    from .linked_doc_generator import LinkedDocumentGenerator
    from .generation_config import GenerationConfig
    
    config = GenerationConfig(
        max_new_tokens=max_new_tokens,
        temperature=temperature,
        top_k=top_k,
        top_p=top_p,
        max_tokens_per_document=max_tokens_per_document,
        max_context_length=self.backbone.max_seq_len,
        max_auxiliary_documents=max_auxiliary_documents,
        max_link_depth=max_link_depth,
        allow_corpus_fallback=allow_corpus_fallback,
        eviction_policy=eviction_policy,
        device=str(next(self.backbone.parameters()).device),
    )
    
    generator = LinkedDocumentGenerator(
        model=self,
        tokenizer_encode=enc.encode,
        tokenizer_decode=enc.decode
    )
    
    # Convert prompt_tokens if provided as Tensor
    if prompt_tokens is not None:
        if isinstance(prompt_tokens, Tensor):
            prompt_tokens = prompt_tokens.cpu().numpy()
    
    return generator.generate(
        prompt=prompt,
        prompt_tokens=prompt_tokens,
        corpus=corpus,
        config=config
    )
```

**Testing**: Integration test with simple prompts

---

## Phase 5: Testing & Validation

### 5.1 Unit Tests (EASY per module)
**Files**: `experiments/dagseq2dagseq/tests/model/test_*.py`

**Dependencies**: Respective modules

**Description**: Create comprehensive unit tests for each module.

**Requirements**:
- One test file per module
- Test all public methods
- Test edge cases and error conditions
- Use pytest fixtures for common setup
- Mock external dependencies where appropriate

**Test Files**:
- `test_document_corpus.py`
- `test_generation_result.py`
- `test_title_utils.py`
- `test_link_detector.py`
- `test_sampling.py`
- `test_document_context.py`
- `test_generation_config.py`
- `test_single_doc_generator.py`
- `test_prompt_processor.py`
- `test_linked_doc_generator.py`

---

### 5.2 Integration Tests (MEDIUM)
**File**: `experiments/dagseq2dagseq/tests/model/test_generation_integration.py`

**Dependencies**: All generation components, trained model

**Description**: End-to-end integration tests with actual model.

**Requirements**:
- Test complete generation pipeline
- Test with small trained model (or random weights for faster testing)
- Test scenarios:
  - Simple generation (no links)
  - Generation with corpus links
  - Generation with generated links
  - Mixed corpus + generated links
  - Max depth enforcement
  - Eviction policies
  - Stopping conditions
- Verify output format and structure
- Performance benchmarks (tokens/second)

---

### 5.3 Example Scripts (EASY)
**File**: `experiments/dagseq2dagseq/examples/generate_example.py`

**Dependencies**: All generation components

**Description**: User-friendly example script demonstrating generation.

**Requirements**:
- Load trained model checkpoint
- Load corpus
- Generate with various configurations
- Display results nicely
- Save outputs to file
- Command-line interface with argparse

**Example Usage**:
```bash
python examples/generate_example.py \
    --model-path runs/20240115_120000/checkpoint_final.pt \
    --corpus-path data/pretokenized/wiki_small/ \
    --prompt "Artificial intelligence is" \
    --max-new-tokens 200 \
    --max-link-depth 2 \
    --temperature 0.8
```

---

## Phase 6: Documentation & Polish

### 6.1 API Documentation (EASY)
**File**: `experiments/dagseq2dagseq/docs/GENERATION_API.md`

**Dependencies**: None

**Description**: Comprehensive API documentation for generation system.

**Requirements**:
- Overview of generation system
- Architecture diagram (text-based)
- API reference for all public classes and methods
- Configuration options explained
- Usage examples
- Common patterns and best practices
- Troubleshooting guide

---

### 6.2 Tutorial Notebook (MEDIUM)
**File**: `experiments/dagseq2dagseq/notebooks/generation_tutorial.ipynb`

**Dependencies**: All generation components

**Description**: Interactive Jupyter notebook walking through generation features.

**Requirements**:
- Introduction to DS2DS generation
- Basic generation examples
- Link-based generation examples
- Corpus integration examples
- Visualization of results (optional)
- Performance optimization tips

---

## Dependency Graph

```
Phase 1 (Foundation - mostly parallelizable):
├── 1.1 DocumentCorpus (no dependencies)
├── 1.2 Title Utilities (no dependencies)
├── 1.3 GenerationResult ← depends on 1.2
├── 1.4 Link Detector (no dependencies, but needs tiktoken)
└── 1.5 Sampling Utilities (no dependencies)

Phase 2 (Context Management):
├── 2.1 DocumentContext ← depends on 1.2, 1.3, 1.4
└── 2.2 GenerationConfig (no dependencies)

Phase 3 (Generation Logic):
├── 3.1 Single Doc Generator ← depends on 2.1, 2.2, 1.5, 1.4
├── 3.2 Prompt Processor ← depends on 1.4, 2.1, 1.1, 1.2
└── 3.3 Linked Doc Generator ← depends on 3.1, 3.2, 1.4, 2.1, 1.1, 1.2, 1.5

Phase 4 (Model Integration):
├── 4.1 forward_inference ← no dependencies (only existing model structure)
└── 4.2 generate method ← depends on 3.3, 2.2, 1.1

Phase 5 (Testing):
├── 5.1 Unit Tests ← depends on respective modules
├── 5.2 Integration Tests ← depends on all components + 4.1, 4.2
└── 5.3 Example Scripts ← depends on all components + 4.1, 4.2

Phase 6 (Documentation):
├── 6.1 API Docs ← depends on all components being complete
└── 6.2 Tutorial ← depends on all components being complete
```

---

## Task Categorization by Difficulty

### EASY (Sub-agent with one-time prompt):
1. DocumentCorpus Class (1.1)
2. Title Normalization Utilities (1.2)
3. GenerationResult Data Structures (1.3)
4. Token Sampling Utilities (1.5)
5. GenerationConfig Dataclass (2.2)
6. Implement generate in DS2DSModel (4.2) - once deps are done
7. Unit Tests per module (5.1) - once modules are done
8. Example Scripts (5.3) - once all is done
9. API Documentation (6.1) - once all is done

**Total EASY: 9 tasks**

### MEDIUM (Primary agent, optional questions):
1. Link Detection Module (1.4)
2. Single Document Generator (3.1)
3. Prompt Link Processor (3.2)
4. Implement forward_inference (4.1)
5. Integration Tests (5.2)
6. Tutorial Notebook (6.2)

**Total MEDIUM: 6 tasks**

### HARD (Primary agent, extensive conversation):
1. DocumentContext Class (2.1)
2. Linked Document Generator (3.3)

**Total HARD: 2 tasks**

---

## Implementation Strategy

### Recommended Order:
1. **Start with Foundation (Phase 1)**: All EASY tasks can be parallelized
2. **Build Context Management (Phase 2)**: DocumentContext (HARD) is critical path
3. **Implement Generation (Phase 3)**: Build up from simple to complex
4. **Integrate with Model (Phase 4)**: Should be quick once Phase 3 is done
5. **Test & Validate (Phase 5)**: Comprehensive testing
6. **Document (Phase 6)**: Final polish

### Orchestration Approach:
- **Batch EASY tasks**: Give to sub-agents with detailed specs
- **Sequence MEDIUM tasks**: One primary agent, can work through them
- **Deep-dive HARD tasks**: Separate conversation per task with primary agent

### Estimated Effort:
- EASY tasks: ~1-2 hours per task (9 tasks = ~9-18 hours)
- MEDIUM tasks: ~2-4 hours per task (6 tasks = ~12-24 hours)
- HARD tasks: ~4-8 hours per task (2 tasks = ~8-16 hours)
- **Total: ~30-60 hours of agent time**

---

## Notes & Considerations

### Critical Path:
`DocumentContext (2.1)` → `Linked Doc Generator (3.3)` → `generate method (4.2)` → `Integration Tests (5.2)`

### Potential Risks:
1. **DocumentContext complexity**: Managing indices and eviction is tricky
2. **Link detection performance**: Checking every token could be slow
3. **FlexAttention recompilation**: Block mask creation on every step may be expensive
4. **Memory management**: Large contexts with many documents could OOM

### Optimization Opportunities (Post-MVP):
1. Cache block masks when context structure doesn't change
2. Batch link detection (check every N tokens)
3. Implement KV caching for faster generation
4. Parallelize corpus lookups
5. Add beam search support
6. Add more sophisticated eviction policies

### Extension Points (Future):
1. Support for non-markdown link formats (LaTeX, Python imports)
2. Fuzzy corpus matching with embeddings
3. Interactive generation (user chooses which links to follow)
4. Link graph visualization
5. Attention pattern analysis tools
6. Multi-document beam search

---

## Validation Checklist

Before considering the implementation complete, verify:
- [ ] All unit tests pass
- [ ] Integration tests pass with trained model
- [ ] Example script runs end-to-end
- [ ] Generated documents have correct structure
- [ ] Corpus documents are loaded correctly
- [ ] Link detection works on real generated text
- [ ] Eviction policies work as expected
- [ ] Max depth is enforced
- [ ] All stopping conditions work
- [ ] Memory usage is reasonable
- [ ] Generation speed is acceptable (>= 10 tokens/sec on GPU)
- [ ] Documentation is complete and accurate
- [ ] Code follows project style guidelines
- [ ] No TODO or FIXME comments remain

---

## Questions for Clarification (Before Implementation)

1. **Model Checkpoint**: Do we have a trained checkpoint to test with, or should we use random weights for initial testing?

2. **Corpus Dataset**: Do we have a small pretokenized corpus ready for testing, or should we create one?

3. **Token Budget Per Document (Training)**: What is the actual `max_tokens_per_document` used during training? This should match for consistency.

4. **Mask Type for Generation**: Which block mask type should we use during generation? `doc_causal` or `cross_doc_link`?

5. **EOS Handling**: Should we automatically append EOS tokens to completed documents, or let the model generate them?

6. **Title Collision**: What happens if the model generates a link to "Python" twice? Reuse the first one, or generate a second "Python_different_hash"?

7. **Empty Target**: What if the model generates `[text]()` with empty target? Skip it?

8. **Performance Requirements**: What's the minimum acceptable generation speed? This affects optimization priorities.

9. **Testing Data**: Can we use a subset of the TAGWiki dataset for testing, or should we create a synthetic mini-corpus?

10. **Device Handling**: Should we support multi-GPU generation, or single device only for MVP?
